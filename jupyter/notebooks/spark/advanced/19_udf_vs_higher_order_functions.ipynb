{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de1e42d6-8351-428f-924c-d1b790550359",
   "metadata": {},
   "source": [
    "# UDF vs Higher order functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "094d2593-004d-41bc-b232-f0a5e1b424b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/06 19:00:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://b9eb03d0898c:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>UDF vs Higher Order Functions</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb80067df90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Spark Session\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"UDF vs Higher Order Functions\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12d0c9dc-9320-4738-b524-85b61bf38d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- cities: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+---+--------------------+\n",
      "| id|              cities|\n",
      "+---+--------------------+\n",
      "|  1|[Bangalore, Mumba...|\n",
      "|  2|         [Bangalore]|\n",
      "|  3|                  []|\n",
      "|  4|[Kolkata, Bhubane...|\n",
      "|  5|[Bangalore, Mumba...|\n",
      "|  6|[Delhi, Mumbai, K...|\n",
      "|  7| [Bangalore, Indore]|\n",
      "|  8|         [Bangalore]|\n",
      "|  9|           [Kolkata]|\n",
      "| 10|      [Bhubaneshwar]|\n",
      "| 11|[Bangalore, Mumba...|\n",
      "| 12|[Chennai, Hyderāb...|\n",
      "| 13|                  []|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example Data Frame\n",
    "\n",
    "_data = [\n",
    "    [1, [\"Bangalore\", \"Mumbai\", \"Pune\", \"Indore\"]],\n",
    "    [2, [\"Bangalore\"]],\n",
    "    [3, []],\n",
    "    [4, [\"Kolkata\", \"Bhubaneshwar\"]],\n",
    "    [5, [\"Bangalore\", \"Mumbai\", \"Pune\", \"Indore\", \"Ahmedabad\", \"Suratkal\"]],\n",
    "    [6, [\"Delhi\", \"Mumbai\", \"Kolkāta\", \"Bangalore\", \"Chennai\", \"Hyderābād\", \"Pune\", \"Ahmedabad\", \"Sūrat\", \"Lucknow\", \"Jaipur\", \"Cawnpore\", \"Mirzāpur\", \"Nāgpur\", \"Ghāziābād\", \"Indore\", \"Vadodara\", \"Vishākhapatnam\", \"Bhopāl\", \"Chinchvad\", \"Patna\", \"Ludhiāna\", \"Āgra\", \"Kalyān\", \"Madurai\", \"Jamshedpur\", \"Nāsik\", \"Farīdābād\", \"Aurangābād\", \"Rājkot\", \"Meerut\", \"Jabalpur\", \"Thāne\", \"Dhanbād\", \"Allahābād\", \"Vārānasi\", \"Srīnagar\", \"Amritsar\", \"Alīgarh\", \"Bhiwandi\", \"Gwalior\", \"Bhilai\", \"Hāora\", \"Rānchi\", \"Bezwāda\", \"Chandīgarh\", \"Mysore\", \"Raipur\", \"Kota\", \"Bareilly\", \"Jodhpur\", \"Coimbatore\", \"Dispur\", \"Guwāhāti\", \"Solāpur\", \"Trichinopoly\", \"Hubli\", \"Jalandhar\", \"Bhubaneshwar\", \"Bhayandar\", \"Morādābād\", \"Kolhāpur\", \"Thiruvananthapuram\", \"Sahāranpur\", \"Warangal\", \"Salem\", \"Mālegaon\", \"Kochi\", \"Gorakhpur\", \"Shimoga\", \"Tiruppūr\", \"Guntūr\", \"Raurkela\", \"Mangalore\", \"Nānded\", \"Cuttack\", \"Chānda\", \"Dehra Dūn\", \"Durgāpur\", \"Āsansol\", \"Bhāvnagar\", \"Amrāvati\", \"Nellore\", \"Ajmer\", \"Tinnevelly\", \"Bīkaner\", \"Agartala\", \"Ujjain\", \"Jhānsi\", \"Ulhāsnagar\", \"Davangere\", \"Jammu\", \"Belgaum\", \"Gulbarga\", \"Jāmnagar\", \"Dhūlia\", \"Gaya\", \"Jalgaon\", \"Kurnool\", \"Udaipur\", \"Bellary\", \"Sāngli\", \"Tuticorin\", \"Calicut\", \"Akola\", \"Bhāgalpur\", \"Sīkar\", \"Tumkūr\", \"Quilon\", \"Muzaffarnagar\", \"Bhīlwāra\", \"Nizāmābād\", \"Bhātpāra\", \"Kākināda\", \"Parbhani\", \"Pānihāti\", \"Lātūr\", \"Rohtak\", \"Rājapālaiyam\", \"Ahmadnagar\", \"Cuddapah\", \"Rājahmundry\", \"Alwar\", \"Muzaffarpur\", \"Bilāspur\", \"Mathura\", \"Kāmārhāti\", \"Patiāla\", \"Saugor\", \"Bijāpur\", \"Brahmapur\", \"Shāhjānpur\", \"Trichūr\", \"Barddhamān\", \"Kulti\", \"Sambalpur\", \"Purnea\", \"Hisar\", \"Fīrozābād\", \"Bīdar\", \"Rāmpur\", \"Shiliguri\", \"Bāli\", \"Pānīpat\", \"Karīmnagar\", \"Bhuj\", \"Ichalkaranji\", \"Tirupati\", \"Hospet\", \"Āīzawl\", \"Sannai\", \"Bārāsat\", \"Ratlām\", \"Handwāra\", \"Drug\", \"Imphāl\", \"Anantapur\", \"Etāwah\", \"Rāichūr\", \"Ongole\", \"Bharatpur\", \"Begusarai\", \"Sonīpat\", \"Rāmgundam\", \"Hāpur\", \"Uluberiya\", \"Porbandar\", \"Pāli\", \"Vizianagaram\", \"Puducherry\", \"Karnāl\", \"Nāgercoil\", \"Tanjore\", \"Sambhal\", \"Naihāti\", \"Secunderābād\", \"Kharagpur\", \"Dindigul\", \"Shimla\", \"Ingrāj Bāzār\", \"Ellore\", \"Puri\", \"Haldia\", \"Nandyāl\", \"Bulandshahr\", \"Chakradharpur\", \"Bhiwāni\", \"Gurgaon\", \"Burhānpur\", \"Khammam\", \"Madhyamgram\", \"Ghāndīnagar\", \"Baharampur\", \"Mahbūbnagar\", \"Mahesāna\", \"Ādoni\", \"Rāiganj\", \"Bhusāval\", \"Bahraigh\", \"Shrīrāmpur\", \"Tonk\", \"Sirsa\", \"Jaunpur\", \"Madanapalle\", \"Hugli\", \"Vellore\", \"Alleppey\", \"Cuddalore\", \"Deo\", \"Chīrāla\", \"Machilīpatnam\", \"Medinīpur\", \"Bāramūla\", \"Chandannagar\", \"Fatehpur\", \"Udipi\", \"Tenāli\", \"Sitalpur\", \"Conjeeveram\", \"Proddatūr\", \"Navsāri\", \"Godhra\", \"Budaun\", \"Chittoor\", \"Harīpur\", \"Saharsa\", \"Vidisha\", \"Pathānkot\", \"Nalgonda\", \"Dibrugarh\", \"Bālurghāt\", \"Krishnanagar\", \"Fyzābād\", \"Silchar\", \"Shāntipur\", \"Hindupur\"]],\n",
    "    [7, [\"Bangalore\", \"Indore\"]],\n",
    "    [8, [\"Bangalore\"]],\n",
    "    [9, [\"Kolkata\", ]],\n",
    "    [10, [\"Bhubaneshwar\"]],\n",
    "    [11, [\"Bangalore\", \"Mumbai\", \"Suratkal\"]],\n",
    "    [12, [\"Chennai\", \"Hyderābād\", \"Pune\", \"Ahmedabad\", \"Sūrat\", \"Lucknow\", \"Jaipur\", \"Cawnpore\"]],\n",
    "    [13, []]\n",
    "]\n",
    "\n",
    "_cols = [\"id\", \"cities\"]\n",
    "\n",
    "# Create Data Frame\n",
    "df = spark.createDataFrame(data = _data, schema = _cols)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f476fe72-6456-4adf-8530-0b7b790cdeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF for len of cities\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "def len_of_cities(col):\n",
    "    _len = 0\n",
    "    for i in col:\n",
    "        _len += len(i)\n",
    "    return _len\n",
    "\n",
    "len_of_cities_udf = F.udf(lambda x: len_of_cities(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf621a87-e246-477b-b138-b3f8230e612c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------------+\n",
      "| id|              cities|len_of_cities|\n",
      "+---+--------------------+-------------+\n",
      "|  1|[Bangalore, Mumba...|           25|\n",
      "|  2|         [Bangalore]|            9|\n",
      "|  3|                  []|            0|\n",
      "|  4|[Kolkata, Bhubane...|           19|\n",
      "|  5|[Bangalore, Mumba...|           42|\n",
      "|  6|[Delhi, Mumbai, K...|         1806|\n",
      "+---+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting the execution time using the UDF\n",
    "\n",
    "df.withColumn(\"len_of_cities\", len_of_cities_udf(\"cities\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3158949-5071-4af7-924c-e4d00283dd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------------+\n",
      "| id|              cities|len_of_cities|\n",
      "+---+--------------------+-------------+\n",
      "|  1|[Bangalore, Mumba...|           25|\n",
      "|  2|         [Bangalore]|            9|\n",
      "|  3|                  []|            0|\n",
      "|  4|[Kolkata, Bhubane...|           19|\n",
      "|  5|[Bangalore, Mumba...|           42|\n",
      "|  6|[Delhi, Mumbai, K...|         1806|\n",
      "+---+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# USE OF AGGREGATE (REDUCE)\n",
    "from pyspark.sql.functions import aggregate, lit, length, size\n",
    "\n",
    "df.withColumn(\"len_of_cities\", F.aggregate(\"cities\", F.lit(0), lambda x, y: x + F.length(y))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4c6c419-d595-4004-9291-81856b1b31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, StringType, BooleanType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ea55b8e-e098-4e8d-bb63-eff8afd7b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE OF TRANSFORM\n",
    "\n",
    "df_upper = df.withColumn(\"upper_cities\", F.transform(\"cities\", lambda x: F.upper(x)))\n",
    "to_upper_udf = F.udf(lambda arr: [x.upper() for x in arr], ArrayType(StringType()))\n",
    "df_upper_udf = df.withColumn(\"upper_cities\", to_upper_udf(F.col(\"cities\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf40607a-7589-4a8d-9a7f-2c06e140d077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upper.write.format(\"noop\").mode(\"overwrite\").save()\n",
    "df_upper_udf.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce139232-b1c2-4489-a833-7ad91e772f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE OF FILTER\n",
    "\n",
    "df_filtered = df.withColumn(\"cities_with_a\", F.filter(\"cities\", lambda x: F.instr(x, 'a') > 0))\n",
    "filter_cities_udf = F.udf(lambda arr: [x for x in arr if 'a' in x], ArrayType(StringType()))\n",
    "df_filtered_udf = df.withColumn(\"cities_with_a\", filter_cities_udf(F.col(\"cities\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4295ab8-4ba1-45da-9e48-90743ec045e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.write.format(\"noop\").mode(\"overwrite\").save()\n",
    "df_filtered_udf.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbe27d1a-aee3-4178-986a-409feede0ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE OF EXISTS\n",
    "\n",
    "df_exists = df.withColumn(\"contains_mumbai\", F.exists(\"cities\", lambda x: x == \"Mumbai\"))\n",
    "contains_mumbai_udf = F.udf(lambda arr: 'Mumbai' in arr, BooleanType())\n",
    "df_exists_udf = df.withColumn(\"contains_mumbai\", contains_mumbai_udf(F.col(\"cities\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0aaa30a-d1f4-4e96-99a1-9aaac5516184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_exists.write.format(\"noop\").mode(\"overwrite\").save()\n",
    "df_exists_udf.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6e12350-29fa-4268-8f0c-63791086d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33faa6-3d49-43a7-80a4-3337bebe9ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
