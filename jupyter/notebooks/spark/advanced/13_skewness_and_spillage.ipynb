{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0622da-9229-4822-8482-b9b76cd3b107",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/26 17:44:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cbedac8cc1fe:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Optimizing Skewness and Spillage</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0e344fdf90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"Optimizing Skewness and Spillage\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.cores.max\", 8)\n",
    "    .config(\"spark.executor.cores\", 4)\n",
    "    .config(\"spark.executor.memory\", \"512M\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99724543-fea0-4b89-996d-cf8cea168bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Disable AQE and Broadcast join\n",
    "\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9191ed11-3ca0-4c15-a3ba-a80bc6fbf9ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read Employee data\n",
    "_schema = \"first_name string, last_name string, job_title string, dob string, email string, phone string, salary double, department_id int\"\n",
    "\n",
    "emp = spark.read.format(\"csv\").schema(_schema).option(\"header\", True).load(\"hdfs://namenode:9000/input/data/employee_records_skewed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68d8df89-6d6a-4e10-99d5-560f8ea0b3fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read DEPT CSV data\n",
    "_dept_schema = \"department_id int, department_name string, description string, city string, state string, country string\"\n",
    "\n",
    "dept = spark.read.format(\"csv\").schema(_dept_schema).option(\"header\", True).load(\"hdfs://namenode:9000/input/data/department_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ba90ff0-a0dc-4a20-bd84-c2389d4ca147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Join Datasets\n",
    "\n",
    "df_joined = emp.join(dept, on=emp.department_id==dept.department_id, how=\"left_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1b613ce-a32a-44d4-bba2-1fa88753df0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_joined.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50625a07-db99-4803-a39e-68707085bfbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|partition_id| count|\n",
      "+------------+------+\n",
      "|         103| 20261|\n",
      "|         122| 19887|\n",
      "|          43|820545|\n",
      "|         107| 19839|\n",
      "|          49| 19799|\n",
      "|          51| 19670|\n",
      "|         102| 20120|\n",
      "|          66| 19946|\n",
      "|         174| 19936|\n",
      "|          89| 19997|\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the partition details to understand distribution\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "part_df = df_joined.withColumn(\"partition_id\", F.spark_partition_id()).groupBy(\"partition_id\").agg(F.count(F.lit(1)).alias(\"count\"))\n",
    "\n",
    "part_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62d80db9-18c9-459e-a1a5-8b395184dde2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|department_id| count|\n",
      "+-------------+------+\n",
      "|            1|820545|\n",
      "|            6| 19799|\n",
      "|            3| 19670|\n",
      "|            5| 19946|\n",
      "|            9| 19997|\n",
      "|            4| 20120|\n",
      "|            8| 20261|\n",
      "|            7| 19839|\n",
      "|           10| 19887|\n",
      "|            2| 19936|\n",
      "+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify Employee data based on department_id\n",
    "emp.groupBy(\"department_id\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "409a7d44-5f4f-4301-9d4f-6e627334d529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set shuffle partitions to a lesser number - 16\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a51cc0a-43bd-4cba-8996-8eece7d97045",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+----------+--------------------+--------------------+--------+-------------+--------------+\n",
      "|first_name| last_name|           job_title|       dob|               email|               phone|  salary|department_id|salted_dept_id|\n",
      "+----------+----------+--------------------+----------+--------------------+--------------------+--------+-------------+--------------+\n",
      "|   Richard|  Morrison|Public relations ...|1973-05-05|melissagarcia@exa...|       (699)525-4827|512653.0|            1|          1_10|\n",
      "|     Bobby|  Mccarthy|   Barrister's clerk|1974-04-25|   llara@example.net|  (750)846-1602x7458|999836.0|            1|           1_3|\n",
      "|    Dennis|    Norman|Land/geomatics su...|1990-06-24| jturner@example.net|    873.820.0518x825|131900.0|           10|          10_3|\n",
      "|      John|    Monroe|        Retail buyer|1968-06-16|  erik33@example.net|    820-813-0557x624|485506.0|            1|           1_5|\n",
      "|  Michelle|   Elliott|      Air cabin crew|1975-03-31|tiffanyjohnston@e...|       (705)900-5337|604738.0|            1|           1_6|\n",
      "|    Ashley|   Montoya|        Cartographer|1976-01-16|patrickalexandra@...|        211.440.5466|483339.0|            1|           1_8|\n",
      "| Nathaniel|     Smith|     Quality manager|1985-06-28|  lori44@example.net|        936-403-3179|419644.0|            1|           1_5|\n",
      "|     Faith|  Cummings|Industrial/produc...|1978-07-01| ygordon@example.org|       (889)246-5588|205939.0|            1|           1_9|\n",
      "|  Margaret|    Sutton|Administrator, ed...|1975-08-16| diana44@example.net|001-647-530-5036x...|671167.0|            1|           1_6|\n",
      "|      Mary|    Sutton|   Freight forwarder|1979-12-28|  ryan36@example.com|   422.562.7254x3159|993829.0|            1|           1_2|\n",
      "|      Jake|      King|       Lexicographer|1994-07-11|monica93@example.org|+1-535-652-9715x6...|702101.0|            1|           1_0|\n",
      "|   Heather|     Haley|         Music tutor|1981-06-01|stephanie65@examp...|   (652)815-7973x298|570960.0|            1|           1_8|\n",
      "|    Thomas|    Thomas|Chartered managem...|2001-07-17|pwilliams@example...|001-245-848-0028x...|339441.0|            1|           1_8|\n",
      "|   Leonard|   Carlson|       Art therapist|1990-10-18|gabrielmurray@exa...|          9247590563|469728.0|            1|           1_9|\n",
      "|      Mark|      Wood|   Market researcher|1963-10-13|nicholas76@exampl...|   311.439.1606x3342|582291.0|            1|           1_0|\n",
      "|    Tracey|Washington|Travel agency man...|1986-05-07|  mark07@example.com|    001-912-206-6456|146456.0|            1|           1_9|\n",
      "|   Rachael| Rodriguez|         Media buyer|1966-12-02|griffinmary@examp...| +1-791-344-7586x548|544732.0|            1|           1_7|\n",
      "|      Tara|       Liu|   Financial adviser|1998-10-12|alexandraobrien@e...|        216.696.6061|399503.0|            1|           1_5|\n",
      "|       Ana|    Joseph|      Retail manager|1995-01-10|  rmorse@example.org|  (726)363-7526x9965|761988.0|            1|           1_2|\n",
      "|   Richard|      Hall|Engineer, civil (...|1967-03-02|brandoncardenas@e...| (964)451-9007x22496|660659.0|            1|           1_2|\n",
      "+----------+----------+--------------------+----------+--------------------+--------------------+--------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Salted Employee\n",
    "salted_emp = emp.withColumn(\"salted_dept_id\", F.concat(\"department_id\", lit(\"_\"), F.round(10*F.rand(), 0).cast(\"int\")))\n",
    "salted_emp.show()                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "60b546aa-5cbd-4915-950b-03a1f1cf7482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 97:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|salted_dept_id|count|\n",
      "+--------------+-----+\n",
      "|           1_2|82469|\n",
      "|           1_7|82305|\n",
      "|           1_3|82234|\n",
      "|           1_4|82232|\n",
      "|           1_9|82209|\n",
      "|           1_1|82133|\n",
      "|           1_5|81999|\n",
      "|           1_6|81836|\n",
      "|           1_8|81663|\n",
      "|          1_10|40739|\n",
      "|           1_0|40726|\n",
      "|           9_9| 2088|\n",
      "|           9_8| 2068|\n",
      "|           5_9| 2066|\n",
      "|           7_3| 2064|\n",
      "|           2_7| 2062|\n",
      "|           2_4| 2057|\n",
      "|           4_8| 2055|\n",
      "|           9_4| 2053|\n",
      "|           4_7| 2045|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "salted_emp.groupby(\"salted_dept_id\").count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ba7f520-7b49-4473-9171-2b4281bbd3da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+-----------+-----+-------+--------------+\n",
      "|department_id|     department_name|         description|       city|state|country|salted_dept_id|\n",
      "+-------------+--------------------+--------------------+-----------+-----+-------+--------------+\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy|           9_5|\n",
      "+-------------+--------------------+--------------------+-----------+-----+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Salted Department\n",
    "\n",
    "salted_dept = dept.withColumn(\"salted_dept_id\", F.concat(\"department_id\", lit(\"_\"), F.round(10*F.rand(), 0).cast(\"int\")))\n",
    "salted_dept.where(\"department_id = 9\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94a09602-ccb0-44df-957e-a5ca7b193805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets make the salted join now\n",
    "salted_joined_df = salted_emp.join(salted_dept, on=salted_emp.salted_dept_id==salted_dept.salted_dept_id, how=\"left_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab8c0bf-ee79-4f88-bf89-38a17c6d24a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "edfbd1c8-5617-4a4b-9c88-97de98079271",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "salted_joined_df.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ebe5989-fe90-4d6b-9645-6534ba497354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|partition_num| count|\n",
      "+-------------+------+\n",
      "|           12|   962|\n",
      "|           18| 92394|\n",
      "|           10| 93205|\n",
      "|            1|  4006|\n",
      "|            3|  5959|\n",
      "|           27| 89132|\n",
      "|           20|  6003|\n",
      "|           29|  5945|\n",
      "|           13|  8043|\n",
      "|           14|  8081|\n",
      "|            6| 89623|\n",
      "|            9|  6197|\n",
      "|           23|130801|\n",
      "|            7| 85772|\n",
      "|           11|  2977|\n",
      "|           26|  3061|\n",
      "|           30|  2032|\n",
      "|           28| 86307|\n",
      "|            8|   966|\n",
      "|            0| 83967|\n",
      "+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the partition details to understand distribution\n",
    "from pyspark.sql.functions import spark_partition_id, count\n",
    "\n",
    "part_df = salted_joined_df.withColumn(\"partition_num\", spark_partition_id()).groupBy(\"partition_num\").agg(count(lit(1)).alias(\"count\"))\n",
    "\n",
    "part_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a30325-65a3-4c65-a499-38147e42ce50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
