{
 "cells": [
  {
   "cell_type": "code",
   "id": "92f7e43a-550e-4b11-8a42-57a2a022d950",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T00:59:38.977161Z",
     "start_time": "2024-10-15T00:59:31.137933Z"
    }
   },
   "source": [
    "# Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"Spark Introduction\")\n",
    "    .config(\"spark.executor.instances\", \"2\")\n",
    "    .config(\"spark.executor.cores\", \"1\")\n",
    "    .config(\"spark.executor.memory\", \"1g\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .getOrCreate()\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/15 00:59:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "9d85b5ec-1e9f-4f03-80ca-029cf50a6518",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T00:59:54.623172Z",
     "start_time": "2024-10-15T00:59:52.829941Z"
    }
   },
   "source": [
    "spark"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fffe80a9750>"
      ],
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://0c293ec01bbd:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Introduction</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "c0656d31-ba16-49f3-8f7f-f0c038d4d886",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T00:59:54.694006Z",
     "start_time": "2024-10-15T00:59:54.687708Z"
    }
   },
   "source": [
    "# Emp Data & Schema\n",
    "\n",
    "emp_data = [\n",
    "    [\"001\",\"101\",\"John Doe\",\"30\",\"Male\",\"50000\",\"2015-01-01\"],\n",
    "    [\"002\",\"101\",\"Jane Smith\",\"25\",\"Female\",\"45000\",\"2016-02-15\"],\n",
    "    [\"003\",\"102\",\"Bob Brown\",\"35\",\"Male\",\"55000\",\"2014-05-01\"],\n",
    "    [\"004\",\"102\",\"Alice Lee\",\"28\",\"Female\",\"48000\",\"2017-09-30\"],\n",
    "    [\"005\",\"103\",\"Jack Chan\",\"40\",\"Male\",\"60000\",\"2013-04-01\"],\n",
    "    [\"006\",\"103\",\"Jill Wong\",\"32\",\"Female\",\"52000\",\"2018-07-01\"],\n",
    "    [\"007\",\"101\",\"James Johnson\",\"42\",\"Male\",\"70000\",\"2012-03-15\"],\n",
    "    [\"008\",\"102\",\"Kate Kim\",\"29\",\"Female\",\"51000\",\"2019-10-01\"],\n",
    "    [\"009\",\"103\",\"Tom Tan\",\"33\",\"Male\",\"58000\",\"2016-06-01\"],\n",
    "    [\"010\",\"104\",\"Lisa Lee\",\"27\",\"Female\",\"47000\",\"2018-08-01\"],\n",
    "    [\"011\",\"104\",\"David Park\",\"38\",\"Male\",\"65000\",\"2015-11-01\"],\n",
    "    [\"012\",\"105\",\"Susan Chen\",\"31\",\"Female\",\"54000\",\"2017-02-15\"],\n",
    "    [\"013\",\"106\",\"Brian Kim\",\"45\",\"Male\",\"75000\",\"2011-07-01\"],\n",
    "    [\"014\",\"107\",\"Emily Lee\",\"26\",\"Female\",\"46000\",\"2019-01-01\"],\n",
    "    [\"015\",\"106\",\"Michael Lee\",\"37\",\"Male\",\"63000\",\"2014-09-30\"],\n",
    "    [\"016\",\"107\",\"Kelly Zhang\",\"30\",\"Female\",\"49000\",\"2018-04-01\"],\n",
    "    [\"017\",\"105\",\"George Wang\",\"34\",\"Male\",\"57000\",\"2016-03-15\"],\n",
    "    [\"018\",\"104\",\"Nancy Liu\",\"29\",\"Female\",\"50000\",\"2017-06-01\"],\n",
    "    [\"019\",\"103\",\"Steven Chen\",\"36\",\"Male\",\"62000\",\"2015-08-01\"],\n",
    "    [\"020\",\"102\",\"Grace Kim\",\"32\",\"Female\",\"53000\",\"2018-11-01\"]\n",
    "]\n",
    "\n",
    "emp_schema = \"employee_id string, department_id string, name string, age string, gender string, salary string, hire_date string\""
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "b1cd7a52-3086-43a9-8e64-dd87eee86c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T00:59:59.477962Z",
     "start_time": "2024-10-15T00:59:55.753580Z"
    }
   },
   "source": [
    "# Create emp DataFrame\n",
    "\n",
    "emp = spark.createDataFrame(data=emp_data, schema=emp_schema)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "cb5c8a76-ab66-42b9-b885-475b7259c4f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T00:57:42.234339Z",
     "start_time": "2024-10-15T00:57:36.136871Z"
    }
   },
   "source": [
    "emp.take(20)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(employee_id='001', department_id='101', name='John Doe', age='30', gender='Male', salary='50000', hire_date='2015-01-01'),\n",
       " Row(employee_id='002', department_id='101', name='Jane Smith', age='25', gender='Female', salary='45000', hire_date='2016-02-15'),\n",
       " Row(employee_id='003', department_id='102', name='Bob Brown', age='35', gender='Male', salary='55000', hire_date='2014-05-01'),\n",
       " Row(employee_id='004', department_id='102', name='Alice Lee', age='28', gender='Female', salary='48000', hire_date='2017-09-30'),\n",
       " Row(employee_id='005', department_id='103', name='Jack Chan', age='40', gender='Male', salary='60000', hire_date='2013-04-01'),\n",
       " Row(employee_id='006', department_id='103', name='Jill Wong', age='32', gender='Female', salary='52000', hire_date='2018-07-01'),\n",
       " Row(employee_id='007', department_id='101', name='James Johnson', age='42', gender='Male', salary='70000', hire_date='2012-03-15'),\n",
       " Row(employee_id='008', department_id='102', name='Kate Kim', age='29', gender='Female', salary='51000', hire_date='2019-10-01'),\n",
       " Row(employee_id='009', department_id='103', name='Tom Tan', age='33', gender='Male', salary='58000', hire_date='2016-06-01'),\n",
       " Row(employee_id='010', department_id='104', name='Lisa Lee', age='27', gender='Female', salary='47000', hire_date='2018-08-01'),\n",
       " Row(employee_id='011', department_id='104', name='David Park', age='38', gender='Male', salary='65000', hire_date='2015-11-01'),\n",
       " Row(employee_id='012', department_id='105', name='Susan Chen', age='31', gender='Female', salary='54000', hire_date='2017-02-15'),\n",
       " Row(employee_id='013', department_id='106', name='Brian Kim', age='45', gender='Male', salary='75000', hire_date='2011-07-01'),\n",
       " Row(employee_id='014', department_id='107', name='Emily Lee', age='26', gender='Female', salary='46000', hire_date='2019-01-01'),\n",
       " Row(employee_id='015', department_id='106', name='Michael Lee', age='37', gender='Male', salary='63000', hire_date='2014-09-30'),\n",
       " Row(employee_id='016', department_id='107', name='Kelly Zhang', age='30', gender='Female', salary='49000', hire_date='2018-04-01'),\n",
       " Row(employee_id='017', department_id='105', name='George Wang', age='34', gender='Male', salary='57000', hire_date='2016-03-15'),\n",
       " Row(employee_id='018', department_id='104', name='Nancy Liu', age='29', gender='Female', salary='50000', hire_date='2017-06-01'),\n",
       " Row(employee_id='019', department_id='103', name='Steven Chen', age='36', gender='Male', salary='62000', hire_date='2015-08-01'),\n",
       " Row(employee_id='020', department_id='102', name='Grace Kim', age='32', gender='Female', salary='53000', hire_date='2018-11-01')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "9ea6550d-86fd-46fd-aeb1-e0ba7c8c84be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T01:00:03.239901Z",
     "start_time": "2024-10-15T01:00:01.737132Z"
    }
   },
   "source": [
    "# Check number of partitions\n",
    "\n",
    "emp.rdd.getNumPartitions()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "8ed4a06b-34e1-443e-ba41-fa2f04f336ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T01:00:09.112919Z",
     "start_time": "2024-10-15T01:00:03.312315Z"
    }
   },
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "emp = emp.withColumn(\"partition_id\", F.spark_partition_id())\n",
    "emp.show()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+------------+\n",
      "|employee_id|department_id|         name|age|gender|salary| hire_date|partition_id|\n",
      "+-----------+-------------+-------------+---+------+------+----------+------------+\n",
      "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|           0|\n",
      "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|           0|\n",
      "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|           1|\n",
      "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|           1|\n",
      "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|           2|\n",
      "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|           2|\n",
      "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|           3|\n",
      "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|           3|\n",
      "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|           3|\n",
      "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|           3|\n",
      "|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|           4|\n",
      "|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|           4|\n",
      "|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|           5|\n",
      "|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|           5|\n",
      "|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|           6|\n",
      "|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|           6|\n",
      "|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|           7|\n",
      "|        018|          104|    Nancy Liu| 29|Female| 50000|2017-06-01|           7|\n",
      "|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|           7|\n",
      "|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|           7|\n",
      "+-----------+-------------+-------------+---+------+------+----------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "058c1ba4-e2b8-4ff3-9d3e-5ed2d8169fcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T01:00:16.544915Z",
     "start_time": "2024-10-15T01:00:13.791158Z"
    }
   },
   "source": [
    "from pyspark import TaskContext\n",
    "import os\n",
    "\n",
    "def get_executor_partition_info(index, iterator):\n",
    "    context = TaskContext.get()\n",
    "    partition_id = context.partitionId()\n",
    "    executor_id = os.getenv(\"SPARK_EXECUTOR_ID\", \"unknown\")\n",
    "    \n",
    "    # Imprimir todas las variables de entorno para ver que SPARK_EXECUTOR_ID existe\n",
    "    print(os.environ)\n",
    "    \n",
    "    return [f\"Executor {executor_id} is processing partition {partition_id}\"]\n",
    "\n",
    "info = emp.rdd.mapPartitionsWithIndex(get_executor_partition_info).collect()\n",
    "\n",
    "for line in info:\n",
    "    print(line)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:============================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor 8d4d02b01ea7 is processing partition 0\n",
      "Executor 8d4d02b01ea7 is processing partition 1\n",
      "Executor de04a8c09e98 is processing partition 2\n",
      "Executor de04a8c09e98 is processing partition 3\n",
      "Executor 8d4d02b01ea7 is processing partition 4\n",
      "Executor de04a8c09e98 is processing partition 5\n",
      "Executor de04a8c09e98 is processing partition 6\n",
      "Executor 8d4d02b01ea7 is processing partition 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "ea3b0dfd-c9ab-49a8-9c72-1ebeb3450d73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T00:47:38.300199Z",
     "start_time": "2024-10-15T00:47:36.838152Z"
    }
   },
   "source": [
    "import socket\n",
    "\n",
    "def get_executor_host(index, iterator):\n",
    "    # Get the hostname of the machine processing this partition (i.e., the executor)\n",
    "    executor_host = socket.gethostname()\n",
    "    \n",
    "    # Get partition ID from TaskContext\n",
    "    context = TaskContext.get()\n",
    "    partition_id = context.partitionId()\n",
    "\n",
    "    return [f\"Executor {executor_host} is processing partition {partition_id}\"]\n",
    "\n",
    "# Apply the function and collect the results\n",
    "info = emp.rdd.mapPartitionsWithIndex(get_executor_host).collect()\n",
    "\n",
    "# Print the collected information on the driver\n",
    "for line in info:\n",
    "    print(line)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:======================>                                    (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor 79fff4e7ee83 is processing partition 0\n",
      "Executor e5ee7fdde0bb is processing partition 1\n",
      "Executor e5ee7fdde0bb is processing partition 2\n",
      "Executor 79fff4e7ee83 is processing partition 3\n",
      "Executor 79fff4e7ee83 is processing partition 4\n",
      "Executor e5ee7fdde0bb is processing partition 5\n",
      "Executor e5ee7fdde0bb is processing partition 6\n",
      "Executor 79fff4e7ee83 is processing partition 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a9a9ddc-0500-487f-bb7f-01f9314f9372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'(8) MapPartitionsRDD[17] at javaToPython at NativeMethodAccessorImpl.java:0 []\\n |  MapPartitionsRDD[16] at javaToPython at NativeMethodAccessorImpl.java:0 []\\n |  SQLExecutionRDD[15] at javaToPython at NativeMethodAccessorImpl.java:0 []\\n |  MapPartitionsRDD[14] at javaToPython at NativeMethodAccessorImpl.java:0 []\\n |  MapPartitionsRDD[4] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0 []\\n |  MapPartitionsRDD[3] at map at SerDeUtil.scala:69 []\\n |  MapPartitionsRDD[2] at mapPartitions at SerDeUtil.scala:117 []\\n |  PythonRDD[1] at RDD at PythonRDD.scala:53 []\\n |  ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:287 []'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp.rdd.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a983c2e6-90c3-4f80-9b42-5e281a53d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write our first Transformation (EMP salary > 50000)\n",
    "\n",
    "emp_final1 = emp.where(\"salary > 50000\")\n",
    "emp_final2 = emp.filter(\"salary > 50000\")\n",
    "emp_final3 = emp.filter(F.col(\"salary\") > 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2870aea-2bf3-411c-aefe-155f44808f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Filter (isnotnull(salary#5) AND (cast(salary#5 as int) > 50000))\n",
      "+- *(1) Project [employee_id#0, department_id#1, name#2, age#3, gender#4, salary#5, hire_date#6, SPARK_PARTITION_ID() AS partition_id#43]\n",
      "   +- *(1) Scan ExistingRDD[employee_id#0,department_id#1,name#2,age#3,gender#4,salary#5,hire_date#6]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_final1.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556440e4-94d1-4881-8773-b31f8ac19b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_final2.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2df2f1-49ed-4059-8b7c-2e96a0cdbcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate number of Partitions\n",
    "\n",
    "emp_final.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf1ed98-c722-437c-8ccc-872ab8d593d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data as CSV output (ACTION)\n",
    "\n",
    "emp_final.write.format(\"csv\").save(\"data/output/1/emp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b2608-7592-4056-9543-8b858bc80090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
